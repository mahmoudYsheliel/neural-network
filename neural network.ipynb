{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "060a6423",
      "metadata": {
        "id": "060a6423"
      },
      "source": [
        "## Project #1\n",
        "## Create a Neural Network In Python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44262c28",
      "metadata": {
        "id": "44262c28"
      },
      "source": [
        "bold text![image-3.png](attachment:image-3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4fb3062",
      "metadata": {
        "id": "a4fb3062"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e2d06c1",
      "metadata": {
        "id": "9e2d06c1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "class out_layer:\n",
        "  def __init__(self,inputs_num,outputs_num):  # type 0 for hidden layer 1 for output layet\n",
        "    self.weigths=(np.random.rand(inputs_num,outputs_num)-0.5)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    self.net=np.dot(np.transpose( self.weigths),inputs)\n",
        "\n",
        "  def output_function(self): #defined as segmoid\n",
        "    o=[2**(-power) for power in  self.net]\n",
        "    self.outputs=[1/(n+1) for n in o]\n",
        "\n",
        "  def func_drev(self):\n",
        "    self.drev=[s*(1-s) for s in self.outputs]\n",
        "\n",
        "  def dE_dO_outpytlayer(self,output):\n",
        "    self.dE_dO=output-self.outputs\n",
        "   \n",
        "  def get_delta(self):\n",
        "    self.delta=[-d*s for d,s in  zip( self.dE_dO,self.drev)]\n",
        "\n",
        "  def w_change(self,prev_out):\n",
        "    #self.delta_w=[-o*p for o,p in zip(prev_out,self.delta)]\n",
        "    self.delta_w=np.outer(prev_out,self.delta)\n",
        "\n",
        "  def update_w(self):\n",
        "    self.weigths=[ w-d for w,d in  zip(self.weigths,self.delta_w)]\n",
        "\n",
        "\n",
        "  def total_forward(self,inputs):\n",
        "    self.forward(inputs)\n",
        "    self.output_function()\n",
        "\n",
        "  def total_backword(self,output,prev_out):\n",
        "    self.func_drev()\n",
        "    self.dE_dO_outpytlayer(output)\n",
        "    self.get_delta()\n",
        "    self.w_change(prev_out)\n",
        "    self.update_w()\n",
        "\n",
        "######################################################\n",
        "\n",
        "class inner_layer:\n",
        "  def __init__(self,inputs_num,outputs_num):  # type 0 for hidden layer 1 for output layet\n",
        "    self.weigths=(np.random.rand(inputs_num,outputs_num)-0.5)\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    self.net=np.dot(np.transpose(self.weigths),inputs)\n",
        "\n",
        "  def output_function(self): #defined as segmoid\n",
        "    o=[2**(-power) for power in  self.net]\n",
        "    self.outputs=[1/(n+1) for n in o]\n",
        "\n",
        "  def func_drev(self):\n",
        "    self.drev=[s*(1-s) for s in self.outputs]\n",
        "\n",
        "  def dE_dO_outpytlayer(self,nex_w,nex_delta):\n",
        "    self.dE_dO=-np.dot( nex_delta,np.transpose( nex_w))\n",
        "   \n",
        "  def get_delta(self):\n",
        "    self.delta=[-d*s for d,s in  zip( self.dE_dO,self.drev)]\n",
        "\n",
        "  def w_change(self,prev_out):\n",
        "    self.delta_w=np.outer(prev_out,self.delta)\n",
        "\n",
        "  def update_w(self):\n",
        "    self.weigths=[ w-d*0.01 for w,d in  zip(self.weigths,self.delta_w)]\n",
        "\n",
        "\n",
        "  def total_forward(self,inputs):\n",
        "    self.forward(inputs)\n",
        "    self.output_function()\n",
        "\n",
        "\n",
        "  def total_backword(self,output,prev_out,nex_w,nex_delta):\n",
        "    self.func_drev()\n",
        "    self.dE_dO_outpytlayer(nex_w,nex_delta)\n",
        "    self.get_delta()\n",
        "    self.w_change(prev_out)\n",
        "    self.update_w()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2d01c92",
      "metadata": {
        "id": "b2d01c92"
      },
      "source": [
        "## Test your model on IRIS  dataset and MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import some data to play with\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data  # we only take the first two features.\n",
        "y = iris.target\n",
        "X_train, X_test,y_train, y_test = train_test_split(X,y ,random_state=104, test_size=0.4, shuffle=True)"
      ],
      "metadata": {
        "id": "EyiYqxkgsO7Q"
      },
      "id": "EyiYqxkgsO7Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b47c1af9",
      "metadata": {
        "id": "b47c1af9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "addc3ae3-642a-4baf-97fd-a41aeff81d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correcet detection percentage =  95.0 %\n"
          ]
        }
      ],
      "source": [
        "l1=inner_layer(4,7) #first layer 4 inputs 7 outputs\n",
        "l2=inner_layer(7,5) #second layer 7 inputs 5 outputs\n",
        "l3=out_layer(5,1) #final layer 5 inputs 1 output\n",
        "\n",
        "for j in range(100): #nuber of times we enter the data to train the model \n",
        "  for inputs,output in zip(X_train,y_train): # take the total data to train the model\n",
        "    output=output/2 # make the data 0,0.5,1 for the three sets (it means normalizing the data)\n",
        "\n",
        "    l1.total_forward(inputs)\n",
        "\n",
        "    l2.total_forward(l1.outputs)\n",
        "\n",
        "    l3.total_forward(l2.outputs)\n",
        "\n",
        "    l3.total_backword(output,l2.outputs)\n",
        "\n",
        "    l2.total_backword(l3.outputs,l1.outputs,l3.weigths,l3.delta)\n",
        "\n",
        "    l1.total_backword(output,inputs,l2.weigths,l2.delta)\n",
        "\n",
        "#test the model\n",
        "number_of_correct_detection=0\n",
        "for x,y in zip(X_test,y_test):\n",
        " \n",
        "  l1.total_forward(x)\n",
        "  l2.total_forward(l1.outputs)\n",
        "  l3.total_forward(l2.outputs)\n",
        "  if np.round(np.dot(2,(l3.outputs)))==y:\n",
        "    number_of_correct_detection+=1\n",
        "\n",
        "print('correcet detection percentage = ',number_of_correct_detection/len(y_test)*100 ,'%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61b11360",
      "metadata": {
        "id": "61b11360"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn import datasets\n",
        "digits = datasets.load_digits() \n",
        "x_data = digits.images.reshape(len(digits.images),8*8)\n",
        "y_data = digits.target.copy()\n",
        "\n",
        "train_X , test_X ,train_y,test_y = train_test_split(x_data,y_data,test_size = 1/4 , shuffle = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee362c0",
      "metadata": {
        "id": "cee362c0"
      },
      "outputs": [],
      "source": [
        "l11=inner_layer(64,200) #first layer 784 inputs 7 outputs\n",
        "l21=inner_layer(200,100) #second layer 7 inputs 5 outputs\n",
        "l31=out_layer(100,10) #final layer 5 inputs 1 output\n",
        "\n",
        "for j in range(20):\n",
        "  for inputs,index in zip(train_X,train_y): # take the total data to train the model\n",
        "    output=np.zeros(10)\n",
        "    output[index]=1\n",
        "\n",
        "    l11.total_forward(inputs)\n",
        "\n",
        "    l21.total_forward(l11.outputs)\n",
        "\n",
        "    l31.total_forward(l21.outputs)\n",
        "\n",
        "    l31.total_backword(output,l21.outputs)\n",
        "\n",
        "    l21.total_backword(l31.outputs,l11.outputs,l31.weigths,l31.delta)\n",
        "\n",
        "    l11.total_backword(output,inputs,l21.weigths,l21.delta)\n",
        "\n",
        "    #test the model\n",
        "number_of_correct_detection=0\n",
        "for x,y in zip(test_X,test_y):\n",
        " \n",
        "  l11.total_forward(x)\n",
        "  l21.total_forward(l11.outputs)\n",
        "  l31.total_forward(l21.outputs)\n",
        "  if np.argmax(l31.outputs)==y:\n",
        "      number_of_correct_detection+=1\n",
        "\n",
        "print('correcet detection percentage = ',number_of_correct_detection/len(test_y)*100 ,'%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff0e3351",
      "metadata": {
        "id": "ff0e3351"
      },
      "source": [
        "## Refrence\n",
        "https://becominghuman.ai/understanding-neural-networks-2-the-math-of-neural-networks-in-3-equations-6085fd3f09df\n",
        "https://towardsdatascience.com/how-to-define-a-neural-network-as-a-mathematical-function-f7b820cde3f\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}